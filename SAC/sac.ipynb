{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e045426-939d-4382-9467-30263646e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU: [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "from tf_agents.environments import suite_gym, ParallelPyEnvironment, tf_py_environment\n",
    "from tf_agents.agents.sac.sac_agent import SacAgent\n",
    "from tf_agents.networks.actor_distribution_network import ActorDistributionNetwork\n",
    "from tf_agents.networks import sequential, nest_map\n",
    "from tf_agents.keras_layers import inner_reshape\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.system import multiprocessing\n",
    "\n",
    "try:\n",
    "    multiprocessing.enable_interactive_mode()\n",
    "except RuntimeError as e:\n",
    "    if \"context has already been set\" not in str(e):\n",
    "        raise\n",
    "except ValueError as e:\n",
    "    if \"Multiprocessing already initialized\" not in str(e):\n",
    "        raise\n",
    "\n",
    "# Habilitar uso de GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for g in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "print(\"Usando GPU:\", tf.config.list_logical_devices('GPU'))\n",
    "\n",
    "# --- Helper para construir red critic personalizada ---\n",
    "dense = functools.partial(tf.keras.layers.Dense, activation='relu', kernel_initializer='glorot_uniform')\n",
    "\n",
    "def create_identity_layer():\n",
    "    return tf.keras.layers.Lambda(lambda x: x)\n",
    "\n",
    "def create_sequential_critic_network(obs_units, act_units, joint_units):\n",
    "    def split(inputs):\n",
    "        return {'observation': inputs[0], 'action': inputs[1]}\n",
    "    obs_net   = sequential.Sequential([dense(u) for u in obs_units]) if obs_units else create_identity_layer()\n",
    "    act_net   = sequential.Sequential([dense(u) for u in act_units]) if act_units else create_identity_layer()\n",
    "    joint_net = sequential.Sequential([dense(u) for u in joint_units]) if joint_units else create_identity_layer()\n",
    "    value_layer = tf.keras.layers.Dense(1, kernel_initializer='glorot_uniform')\n",
    "    return sequential.Sequential([\n",
    "        tf.keras.layers.Lambda(split),\n",
    "        nest_map.NestMap({'observation': obs_net, 'action': act_net}),\n",
    "        nest_map.NestFlatten(),\n",
    "        tf.keras.layers.Concatenate(),\n",
    "        joint_net,\n",
    "        value_layer,\n",
    "        inner_reshape.InnerReshape(current_shape=[1], new_shape=[])\n",
    "    ], name='sequential_critic')\n",
    "\n",
    "\n",
    "def run_sac_seed(seed,\n",
    "                 #env_name = \"MountainCarContinuous-v0\",\n",
    "                 env_name=\"Pendulum-v1\",\n",
    "                 num_parallel=64*4,\n",
    "                 collect_steps=128*2,\n",
    "                 batch_size=256*4,\n",
    "                 replay_buffer_max=200_000,\n",
    "                 learning_rate=1e-4,\n",
    "                 num_iterations=100_000,#50_000,\n",
    "                 eval_interval=5_000):\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    random.seed(seed); np.random.seed(seed); tf.random.set_seed(seed)\n",
    "\n",
    "    def make_env(): return suite_gym.load(env_name)\n",
    "    py_env = ParallelPyEnvironment([make_env] * num_parallel)\n",
    "    train_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "    eval_env  = tf_py_environment.TFPyEnvironment(suite_gym.load(env_name))\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        train_step = tf.Variable(0)\n",
    "\n",
    "        actor_net  = ActorDistributionNetwork(\n",
    "            train_env.observation_spec(),\n",
    "            train_env.action_spec(),\n",
    "            fc_layer_params=(256,256)\n",
    "        )\n",
    "        critic_net1 = create_sequential_critic_network((256,256), None, (256,256))\n",
    "        critic_net2 = create_sequential_critic_network((256,256), None, (256,256))\n",
    "\n",
    "        agent = SacAgent(\n",
    "            time_step_spec=train_env.time_step_spec(),\n",
    "            action_spec=train_env.action_spec(),\n",
    "            actor_network=actor_net,\n",
    "            critic_network=critic_net1,\n",
    "            critic_network_2=critic_net2,\n",
    "            actor_optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "            critic_optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "            alpha_optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "            target_update_tau=0.005,\n",
    "            target_update_period=1,\n",
    "            td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "            gamma=0.99,\n",
    "            reward_scale_factor=2.0,\n",
    "            train_step_counter=train_step\n",
    "        )\n",
    "        agent.initialize()\n",
    "        agent.train = common.function(agent.train)\n",
    "\n",
    "    buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "        data_spec=agent.collect_data_spec,\n",
    "        batch_size=num_parallel,\n",
    "        max_length=replay_buffer_max\n",
    "    )\n",
    "    dataset = buffer.as_dataset(sample_batch_size=batch_size, num_steps=2).prefetch(tf.data.AUTOTUNE)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    driver = dynamic_step_driver.DynamicStepDriver(\n",
    "        train_env, agent.collect_policy, observers=[buffer.add_batch], num_steps=collect_steps\n",
    "    )\n",
    "    driver.run()  # Warm-up\n",
    "\n",
    "    @tf.function\n",
    "    def train_step_fn():\n",
    "        experience, _ = next(iterator)\n",
    "        return agent.train(experience)\n",
    "\n",
    "    episodes = []\n",
    "    evals = []\n",
    "    ep_rewards = np.zeros(num_parallel)\n",
    "    ep_steps = np.zeros(num_parallel, dtype=int)\n",
    "    ep_count = np.zeros(num_parallel, dtype=int)\n",
    "\n",
    "    def update_episodes(time_step):\n",
    "        nonlocal ep_rewards, ep_steps, ep_count\n",
    "        rewards = time_step.reward.numpy()\n",
    "        dones = time_step.is_last().numpy()\n",
    "        ep_rewards += rewards\n",
    "        ep_steps += 1\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                ep_count[i] += 1\n",
    "                episodes.append({\n",
    "                    \"total_timesteps\": int(ep_steps[i]),\n",
    "                    \"episode_num\": int(ep_count[i]),\n",
    "                    \"episode_timesteps\": int(ep_steps[i]),\n",
    "                    \"reward\": float(ep_rewards[i])\n",
    "                })\n",
    "                ep_rewards[i] = 0.0\n",
    "                ep_steps[i] = 0\n",
    "\n",
    "    start_time = datetime.now().isoformat(timespec='seconds')\n",
    "\n",
    "    pbar = trange(num_iterations + 1, desc=f\"Seed {seed}\", dynamic_ncols=True)\n",
    "    pbar.set_postfix({\"eval_return\": \"N/A\"})\n",
    "    for step in pbar:\n",
    "        time_step, _ = driver.run()\n",
    "        update_episodes(time_step)\n",
    "        train_step_fn()\n",
    "\n",
    "        if step % eval_interval == 0:\n",
    "            ts = eval_env.reset(); total = 0.0\n",
    "            while not ts.is_last():\n",
    "                action_step = agent.policy.action(ts)\n",
    "                ts = eval_env.step(action_step.action)\n",
    "                total += ts.reward.numpy().item()\n",
    "            evals.append({\n",
    "                \"at_timesteps\": int(step),\n",
    "                \"evaluation_over_1_episode\": float(total)\n",
    "            })\n",
    "            print(f\"[Step {step:>5}] Eval return = {total:.2f}\")\n",
    "            pbar.set_postfix({\"eval_return\": f\"{total:.2f}\"})\n",
    "            pbar.update(0)\n",
    "\n",
    "    data = {\n",
    "        \"experiment\": {\n",
    "            \"policy\": \"SAC\",\n",
    "            \"environment\": env_name,\n",
    "            \"seed\": seed,\n",
    "            \"start_time\": start_time\n",
    "        },\n",
    "        \"episodes\": episodes,\n",
    "        \"evaluations\": evals\n",
    "    }\n",
    "\n",
    "    folder = \"jsons\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "    fname = f\"sac_{seed}_{ts}.json\"\n",
    "    path = os.path.join(folder, fname)\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved JSON to {path}\")\n",
    "\n",
    "    return episodes, evals, agent\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    seeds = [0]\n",
    "    for s in seeds:\n",
    "        eps, evs = run_sac_seed(seed=s)\n",
    "        steps = [e['at_timesteps'] for e in evs]\n",
    "        vals = [e['evaluation_over_1_episode'] for e in evs]\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(steps, vals, marker='o')\n",
    "        plt.xlabel('Steps'); plt.ylabel('Eval Return')\n",
    "        plt.title(f'SAC Eval (seed {s})')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e9f706-ea13-4e59-90c6-af85b90bb5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe19678-873f-4ba6-ae52-eacc3089139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/system/system_multiprocessing.py\", line 158, in __call__\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/environments/parallel_py_environment.py\", line 458, in _worker\n",
      "    env = cloudpickle.loads(self._pickled_env_constructor)()\n",
      "  File \"/tmp/2641513/ipykernel_3829108/1698676426.py\", line 73, in make_env\n",
      "    def make_env(): return suite_gym.load(env_name)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/gin/config.py\", line 1582, in gin_wrapper\n",
      "    return fn(*new_args, **new_kwargs)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/environments/suite_gym.py\", line 84, in load\n",
      "    gym_env = gym_spec.make(**gym_kwargs)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/gym/envs/registration.py\", line 140, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/gym/envs/classic_control/pendulum.py\", line 101, in __init__\n",
      "    self.observation_space = spaces.Box(low=-high, high=high, dtype=np.float32)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/gym/spaces/box.py\", line 89, in __init__\n",
      "    self.high_repr = _short_repr(self.high)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/gym/spaces/box.py\", line 19, in _short_repr\n",
      "    return str(arr)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 1592, in _array_str_implementation\n",
      "    return array2string(a, max_line_width, precision, suppress_small, ' ', \"\")\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 736, in array2string\n",
      "    return _array2string(a, options, separator, prefix)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 513, in wrapper\n",
      "    return f(self, *args, **kwargs)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 539, in _array2string\n",
      "    format_function = _get_format_function(data, **options)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 472, in _get_format_function\n",
      "    return formatdict['float']()\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 411, in <lambda>\n",
      "    'float': lambda: FloatingFormat(\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 932, in __init__\n",
      "    self.fillFormat(data)\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/arrayprint.py\", line 941, in fillFormat\n",
      "    max_val = np.max(abs_non_zero)\n",
      "  File \"<__array_function__ internals>\", line 180, in amax\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 2793, in amax\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "  File \"/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m seeds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[0;32m----> 3\u001b[0m     eps, evs,agent \u001b[38;5;241m=\u001b[39m \u001b[43mrun_sac_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Plot evaluation returns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     steps \u001b[38;5;241m=\u001b[39m [e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat_timesteps\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m evs]\n",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m, in \u001b[0;36mrun_sac_seed\u001b[0;34m(seed, env_name, num_parallel, collect_steps, batch_size, replay_buffer_max, learning_rate, num_iterations, eval_interval)\u001b[0m\n\u001b[1;32m     71\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seed); np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed); tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(seed)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_env\u001b[39m(): \u001b[38;5;28;01mreturn\u001b[39;00m suite_gym\u001b[38;5;241m.\u001b[39mload(env_name)\n\u001b[0;32m---> 74\u001b[0m py_env \u001b[38;5;241m=\u001b[39m \u001b[43mParallelPyEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmake_env\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_parallel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m train_env \u001b[38;5;241m=\u001b[39m tf_py_environment\u001b[38;5;241m.\u001b[39mTFPyEnvironment(py_env)\n\u001b[1;32m     76\u001b[0m eval_env  \u001b[38;5;241m=\u001b[39m tf_py_environment\u001b[38;5;241m.\u001b[39mTFPyEnvironment(suite_gym\u001b[38;5;241m.\u001b[39mload(env_name))\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/environments/parallel_py_environment.py:89\u001b[0m, in \u001b[0;36mParallelPyEnvironment.__init__\u001b[0;34m(self, env_constructors, start_serially, blocking, flatten)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking \u001b[38;5;241m=\u001b[39m blocking\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_serially \u001b[38;5;241m=\u001b[39m start_serially\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maction_spec()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observation_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mobservation_spec()\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/environments/parallel_py_environment.py:103\u001b[0m, in \u001b[0;36mParallelPyEnvironment.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpawning all processes.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envs:\n\u001b[0;32m--> 103\u001b[0m   \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_to_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_serially\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_serially:\n\u001b[1;32m    105\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaiting for all processes to start.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/environments/parallel_py_environment.py:275\u001b[0m, in \u001b[0;36mProcessPyEnvironment.start\u001b[0;34m(self, wait_to_start)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait_to_start:\n\u001b[0;32m--> 275\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tf_agents/environments/parallel_py_environment.py:279\u001b[0m, in \u001b[0;36mProcessPyEnvironment.wait_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Wait for the started process to finish initialization.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/sac-tfagents/lib/python3.8/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seeds = [0,1,2]\n",
    "for s in seeds:\n",
    "    eps, evs,agent = run_sac_seed(seed=s)\n",
    "\n",
    "    # Plot evaluation returns\n",
    "    steps = [e['at_timesteps'] for e in evs]\n",
    "    vals = [e['evaluation_over_1_episode'] for e in evs]\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(steps, vals, marker='o', label='Eval Return')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Eval Return')\n",
    "    plt.title(f'SAC Eval (seed {s})')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    window = 100\n",
    "    rewards = [e['reward'] for e in eps]\n",
    "    avg_rewards = [np.mean(rewards[i:i+window]) for i in range(0, len(rewards) - window + 1, window)]\n",
    "    \n",
    "    plt.plot(avg_rewards)\n",
    "    plt.xlabel(\"Episode window (x100)\")\n",
    "    plt.ylabel(\"Avg reward per 100 episodes\")\n",
    "    plt.title(\"Smoothed Episode Rewards\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df2862-23a0-4964-b29b-7df541999a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 22:17:20.302672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype resource\n",
      "\t [[{{node Placeholder/_13}}]]\n",
      "2025-05-19 22:17:20.303102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype resource\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "Seed 0:   0%|             | 5/100001 [00:04<41:17, 40.37it/s, eval_return=-911.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step     0] Eval return = -911.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:   5%|▍       | 5003/100001 [03:49<8:29:56,  3.10it/s, eval_return=-296.50]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step  5000] Eval return = -296.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  10%|▋      | 10004/100001 [07:35<5:56:39,  4.21it/s, eval_return=-125.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 10000] Eval return = -125.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  15%|█      | 15004/100001 [11:21<5:31:52,  4.27it/s, eval_return=-124.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 15000] Eval return = -124.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  20%|█▍     | 20005/100001 [15:06<5:18:57,  4.18it/s, eval_return=-124.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 20000] Eval return = -124.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  25%|█▊     | 25005/100001 [18:50<4:54:08,  4.25it/s, eval_return=-118.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 25000] Eval return = -118.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  30%|██     | 30003/100001 [22:34<6:13:01,  3.13it/s, eval_return=-125.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 30000] Eval return = -125.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  35%|██▍    | 35004/100001 [26:17<4:19:17,  4.18it/s, eval_return=-117.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 35000] Eval return = -117.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  40%|██▊    | 40005/100001 [30:01<3:56:26,  4.23it/s, eval_return=-121.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 40000] Eval return = -121.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  45%|███▏   | 45003/100001 [33:43<4:45:10,  3.21it/s, eval_return=-123.60]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 45000] Eval return = -123.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  50%|████▌    | 50004/100001 [37:25<3:13:47,  4.30it/s, eval_return=-8.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 50000] Eval return = -8.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  55%|███▊   | 55005/100001 [41:07<2:59:30,  4.18it/s, eval_return=-137.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 55000] Eval return = -137.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  60%|████▊   | 60003/100001 [44:50<3:28:25,  3.20it/s, eval_return=-12.30]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 60000] Eval return = -12.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  65%|████▌  | 65004/100001 [48:31<2:15:06,  4.32it/s, eval_return=-134.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 65000] Eval return = -134.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  70%|████▉  | 70005/100001 [52:13<1:56:01,  4.31it/s, eval_return=-126.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 70000] Eval return = -126.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  75%|█████▎ | 75003/100001 [55:56<2:12:36,  3.14it/s, eval_return=-130.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 75000] Eval return = -130.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  80%|█████▌ | 80003/100001 [59:42<1:44:07,  3.20it/s, eval_return=-133.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 80000] Eval return = -133.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  85%|███████▋ | 85004/100001 [1:03:24<59:13,  4.22it/s, eval_return=-5.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 85000] Eval return = -5.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  90%|██████▎| 90005/100001 [1:07:06<38:57,  4.28it/s, eval_return=-124.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 90000] Eval return = -124.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0:  95%|██████▋| 95003/100001 [1:10:49<27:06,  3.07it/s, eval_return=-351.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 95000] Eval return = -351.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed 0: 100%|██████| 100001/100001 [1:14:32<00:00, 22.36it/s, eval_return=-127.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 100000] Eval return = -127.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to jsons/sac_0_20250519T233153.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "seeds = [0, 1, 2,3]\n",
    "all_rewards = []\n",
    "\n",
    "for s in seeds:\n",
    "    eps, evs, agent = run_sac_seed(seed=s)\n",
    "\n",
    "    # Store episode rewards\n",
    "    rewards = [e['reward'] for e in eps]\n",
    "    all_rewards.append(rewards)\n",
    "\n",
    "# Find the minimum common length (in case training was cut short)\n",
    "min_len = min(len(r) for r in all_rewards)\n",
    "all_rewards = [r[:min_len] for r in all_rewards]\n",
    "\n",
    "# Convert to numpy array for easier math\n",
    "reward_array = np.array(all_rewards)  # shape: (seeds, episodes)\n",
    "mean_rewards = np.mean(reward_array, axis=0)\n",
    "std_rewards = np.std(reward_array, axis=0)\n",
    "\n",
    "episodes = np.arange(min_len)\n",
    "\n",
    "# Linear trend line\n",
    "slope, intercept, *_ = linregress(episodes, mean_rewards)\n",
    "trend_line = slope * episodes + intercept\n",
    "\n",
    "# Plot: Mean ± Std Dev and Trend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(episodes, mean_rewards, color='blue', label='Mean Reward')\n",
    "plt.fill_between(episodes, mean_rewards - std_rewards, mean_rewards + std_rewards, color='blue', alpha=0.2, label='±1 Std Dev')\n",
    "plt.plot(episodes, trend_line, 'r--', label=f\"Trend: {slope:.2f}x + {intercept:.2f}\")\n",
    "\n",
    "plt.title('Mean Episode Rewards Across Seeds - SAC on Pendulum-v1')#MountainCarContinuous-v0')\n",
    "plt.xlabel('Episode Number')\n",
    "plt.ylabel('Mean Total Reward')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2mountaincar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16666e7d-22e3-46b0-92f1-19b7026604a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.agents.sac.sac_agent.SacAgent at 0x7f8685a00730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40dcc81-bac1-4dfa-b90c-e793ca6346ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation with unsupported characters which will be renamed to step_type, reward, discount, observation in the SavedModel.\n",
      "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
      "WARNING:absl:`0/reward` is not a valid tf.function parameter name. Sanitizing to `arg_0_reward`.\n",
      "WARNING:absl:`0/discount` is not a valid tf.function parameter name. Sanitizing to `arg_0_discount`.\n",
      "WARNING:absl:`0/observation` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation`.\n",
      "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
      "WARNING:absl:Found untraced functions such as ActorDistributionNetwork_layer_call_fn, ActorDistributionNetwork_layer_call_and_return_conditional_losses, EncodingNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses, NormalProjectionNetwork_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n",
      "/home/pinoprie/.local/share/mamba/envs/sac-tfagents/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:497: UserWarning: Encoding a StructuredValue with type tfp.distributions.MultivariateNormalDiag_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_policypendulum1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_policypendulum1/assets\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "# after agent.initialize() and training finishes:\n",
    "saver = policy_saver.PolicySaver(agent.policy)\n",
    "saver.save('saved_policypendulum1')   # this will create a directory 'saved_policy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f63138-5202-4bd1-b2ce-e3b532c97b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pinoprie/new_rl/RL-project/SAC/my_folderpend1.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Replace 'my_folder' with your folder name\n",
    "shutil.make_archive('my_folderpend1', 'zip', 'saved_policypendulum1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713f7350-6a46-4b9c-afdd-61651626e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip -r my_folder.zip saved_policy/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cfb8f2-29ce-4565-bee9-68a94b05c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "print(gym.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7ac9b2d-63b2-4066-83c2-9ae69fd96fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.12.0\n",
      "TF-Agents: 0.17.0\n",
      "TensorFlow Probability: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"TF-Agents:\", tf_agents.__version__)\n",
    "print(\"TensorFlow Probability:\", tfp.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86169a5-de81-469b-af85-ebf5b4a62941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install \"tensorflow==2.12.0\" \"tensorflow-probability==0.20.1\" \"tf-agents==0.17.0\" \"gym==0.23.0\" \"numpy>=1.23\" \"matplotlib>=3.5\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
